(function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
module.exports={
  "APP": "inferrer",
  "SVM_OPTIONS": {
    "c": 3,
    "gamma": 0.1,
    "kernel": "linear",
    "tolerance": 0.001
  }
}

},{}],2:[function(require,module,exports){
module.exports = require("./src/svm")

},{"./src/svm":5}],3:[function(require,module,exports){
module.exports = {
  direction,
  dotProduct,
  euclideanDistance,
  euclideanDistanceSquared,
  geometricMargin,
  hypothesis,
  magnitude,
  sign,
  vectorDiff,
  vectorSum,
}

// Dependencies
const Util = require("./util")

/* Given a vector returns a vector that indicates the direction of the first.
**
** In the simplest terms, direction of a vector is equal to the cosine of
** it's angles. Also known as a unit vector of the original.
*/
// direction :: [ Number ] -> [ Number ]
function direction (v) {
  if (!Util.isArr(v)) {
    throw new TypeError("Direction expects an array of numbers")
  }

  if (!v.every((x) => Util.isNum(x))) {
    throw new TypeError("Direction expects an array of numbers")
  }

  const mag = magnitude(v)

  return v.map((x) => x / mag)
}

/* Given two equal-sized arrays of numbers, the dot product is defined as the
** sum of products of each of the array items.
*/
// dotProduct :: [ Number ], [ Number ] -> Number
function dotProduct (v, w) {
  if (v.length !== w.length) {
    throw new TypeError("Dot Product expects two equal-sized arrays")
  }

  if (!Util.isArr(v) || !Util.isArr(w)) {
    throw new TypeError("Dot Product expects two arrays of numbers")
  }

  if ((!v.every((x) => Util.isNum(x))) || (!w.every((x) => Util.isNum(x)))) {
    const errMsg = "Arrays passed to Dot Product must contain only numbers"

    throw new TypeError(errMsg)
  }

  return v
    .map((x, idx) => x * w[idx])
    .reduce((x, xs) => x + xs, 0)
}

/* The Euclidean distance function will return a straight-line distance
** between two points.
*/
// euclideanDistance :: [ Number ] -> [ Number ] -> Number
function euclideanDistance (v, w) {
  if (v.length !== w.length) {
    throw new TypeError("Euclidean Distance expects two equal-sized arrays")
  }

  if (!Util.isArr(v) || !Util.isArr(w)) {
    throw new TypeError("Euclidean Distance expects two arrays of numbers")
  }

  if ((!v.every((x) => Util.isNum(x))) || (!w.every((x) => Util.isNum(x)))) {
    const errMsg = `
      Arrays passed to Euclidean Distance must contain only numbers
    `

    throw new TypeError(errMsg)
  }

  return Math.sqrt(euclideanDistanceSquared(v, w))
}

/* The Euclidean distance squared function follows the same logic as the
** Euclidean distance function, with the exception that we do not square root
** the result. It is a key component in the Gaussian (RBF) kernel.
*/
// euclideanDistanceSquared :: [ Number ] -> [ Number ] -> Number
function euclideanDistanceSquared (v, w) {
  if (v.length !== w.length) {
    const errMsg = "Euclidean Distance Squared expects two equal-sized arrays"

    throw new TypeError(errMsg)
  }

  if (!Util.isArr(v) || !Util.isArr(w)) {
    const errMsg = "Euclidean Distance Squared expects two arrays of numbers"

    throw new TypeError(errMsg)
  }

  if ((!v.every((x) => Util.isNum(x))) || (!w.every((x) => Util.isNum(x)))) {
    const errMsg = `
      Arrays passed to Euclidean Distance Squared must contain only numbers
    `

    throw new TypeError(errMsg)
  }

  return v.reduce((x, xs, idx) => x + Math.pow((xs - w[idx]), 2), 0)
}

/* The geometric margin is used to calculate the distance between a given
** vector and a hyperplane. In this context, w represents our examples, y
** represents the classifications of w, and v represents our separating
** hyperplane.
*/
// geometricMargin :: [ Number ], [ [ Number ] ], [ Number ], Number -> Number
function geometricMargin (v, w, y, b) {
  if (!Util.isArr(v) || !Util.isArr(w) || !Util.isArr(y) || !Util.isNum(b)) {
    throw new TypeError("Geometric Margin expects three arrays and a number")
  }

  if (!y.every((x) => x == 1 || x == -1)) {
    throw new TypeError("Geometric Margin expects 'y' to be either 1 or -1")
  }

  const exampleMargin = (wi, yi) => {
    return yi * (dotProduct(direction(v), wi) + b / magnitude(v))
  }

  return w
    .map((wi, idx) => exampleMargin(wi, y[idx]))
    .reduce((x, xs) => x > xs ? xs : x) // Return smallest value in array
}

/* Given vectors v and w, we determine how to classify the examples (w) by
** using the equation sign(v . w + b). Within this function, we assume
** v represents our hyperplane, and w represents the input to classify.
*/
// hypothesis :: [ Number ], [ Number ], Number -> Number
function hypothesis (v, w, b) {
  if (!Util.isArr(v) || !Util.isArr(w) || !Util.isNum(b)) {
    throw new TypeError("Hypothesis expects two arrays and a number")
  }

  return sign(dotProduct(v, w) + b)
}

/* A magnitude of a vector is also known as the vector's norm. Magnitude can
** be solved using Euclidean Norm.
** https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm
*/
// magnitude :: [ Number ] -> Number
function magnitude (v) {
  if (!Util.isArr(v)) {
    throw new TypeError("Magnitude expects an array of numbers")
  }

  if (!v.every((x) => Util.isNum(x))) {
    throw new TypeError("Magnitude expects an array of numbers")
  }

  return Math.sqrt(v.reduce((x, xs) => (Math.pow(xs, 2) + x), 0))
}

/* The sign of number x is 1 if x is greater than 0, -1 if x is less than 0,
** and 0 if x is equal to 0. For simplicity, however, we are defaulting
** 0 values to negatives. This means that if a test data example falls
** directly upon the hyperplane, it defaults to a negative value.
*/
// sign :: Number -> Number
function sign (x) {
  if (!Util.isNum(x)) {
    throw new TypeError("Sign expects a number")
  }

  if (x > 0) {
    return 1
  }

  return -1
}

/* Two vectors may be subtracted, resulting in a third vector which is the
** difference of the coordinates of the original two.
*/
// vectorDiff :: [ Number ], [ Number ] -> [ Number ]
function vectorDiff (v, w) {
  if (v.length !== w.length) {
    throw new TypeError("Vector Diff expects two equal-sized arrays")
  }

  if ((!v.every((x) => Util.isNum(x))) || (!w.every((x) => Util.isNum(x)))) {
    throw new TypeError("Vector Diff expects two arrays of numbers")
  }

  return v.map((x, idx) => x - w[idx])
}

/* Two vectors may be added together, resulting in a third vector which is
** the sum of the coordinates of the original two.
*/
// vectorSum :: [ Number ], [ Number ] -> [ Number ]
function vectorSum (v, w) {
  if (v.length !== w.length) {
    throw new TypeError("Vector Sum expects two equal-sized arrays")
  }

  if ((!v.every((x) => Util.isNum(x))) || (!w.every((x) => Util.isNum(x)))) {
    throw new TypeError("Vector Sum expects two arrays of numbers")
  }

  return v.map((x, idx) => x + w[idx])
}

},{"./util":6}],4:[function(require,module,exports){
module.exports = {
  gaussian,
  linear,
}

// Dependencies
const Formula = require("./formula")
const Util = require("./util")

/* As a general note, I'd like to keep this file as clean and easy to follow
** as possible. Therefore, as much type checking as possible should be handled
** by formula functions.
*/

/* The Gaussian (RBF) kernel can be used when the training dataset takes an
** abstract form. The Gaussian kernel projects n-dimensional vectors into an
** n + 1 dimensional space. Takes two equal-sized vectors and a "gamma"
** parameter, which represents the "spread" of the vector. A gamma value too
** large can result in a classifier that is far too focused, while a smaller
** value may create a classifier that is too linear. We default gamma to 0.1.
*/
// gaussian :: [ Number ], [ Number ] -> Number
function gaussian(v, w, gamma) {
  if (!Util.isNum(gamma)) {
    throw new TypeError("Gaussian kernel expects gamma to be a number")
  }

  return Math.exp((-gamma) * Formula.euclideanDistanceSquared(v, w))
}

/* A linear kernel takes two equal-sized vectors and outputs the dot product
** thereunto pertaining.
*/
// linear :: [ Number ], [ Number ] -> Number
function linear(v, w) {
  return Formula.dotProduct(v, w)
}

},{"./formula":3,"./util":6}],5:[function(require,module,exports){
// Dependencies
const Defaults = require("../env/defaults")
const Formula = require("./formula")
const Kernel = require("./kernel")
const Util = require("./util")

/* The SVM class is based on John C. Platt's SMO algorithm. The documentation
** thereunto pertaining can be found here:
** https://microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-14.pdf
*/
module.exports = class Svm {
  constructor (opts = {}) {
    // Optional Properties
    Util.isNum(opts.c)
      ? this.c = opts.c
      : this.c = Defaults.SVM_OPTIONS.c

    Util.isNum(opts.gamma)
      ? this.gamma = opts.gamma
      : this.gamma = Defaults.SVM_OPTIONS.gamma

    Util.isKernel(opts.kernel)
      ? this.kernel = opts.kernel
      : this.kernel = Defaults.SVM_OPTIONS.kernel

    Util.isNum(opts.tolerance)
      ? this.tolerance = opts.tolerance
      : this.tolerance = Defaults.SVM_OPTIONS.tolerance

    this.trained = false
  }

  kern (v, w) {
    // TODO: Implement polynomial kernel functions
    switch (this.kernel) {
      case "gaussian":
        return Kernel.gaussian(v, w, this.gamma)

      case "linear":
        return Kernel.linear(v, w)

      default:
        return Kernel.linear(v, w) // Default to linear kernel function
    }
  }

  /* alias TrainingData =
  **   [ { input: [ Number ], classification: Number } ]
  */
  // train :: TrainingData -> Void
  train (data) {
    // Check data to ensure it is properly formed, expects the following:
    if (!Util.isArr(data) || !data.every((x) => x instanceof Object)) {
      const errMsg = `
        Inferrer requires training data in the form of a list of objects,
        each containing input and classification keys
      `

      throw new TypeError(errMsg)
    }

    if (!data.every((x) => x.input.length === data[0].input.length)) {
      throw new TypeError("All input vectors must be of equal length")
    }

    if (!data.every((x) => x.classification === 1 || x.classification === -1)) {
      throw new TypeError("Every classification must be either 1 or -1")
    }

    // If data is sanitary, include as training data
    this.x = data.map((x) => x.input) // Training examples
    this.y = data.map((x) => x.classification) // Training labels
    this.m = this.x.length // Amount of training examples
    this.w = Array(this.x[0].length).fill(0) // Linear hyperplane
    this.b = 0 // Offset
    this.alpha = Array(this.m).fill(0) // Alphas
    this.error = Array(this.m).fill(0) // Errors

    // Find hyperplane and offset using John C. Platt's SMO Algorithm
    let changed = 0, examineAll = true

    while (changed > 0 || examineAll) {
      changed = 0

      // Examine every example
      if (examineAll) {
        // eslint-disable-next-line no-unused-vars
        Array(this.m).fill(0).forEach((mi, i) => changed += this.examine(i))
      }

      // First heuristic
      else {
        this.alpha.forEach((ai, i) => {
          if (ai !== 0 && ai !== this.c) {
            changed += this.examine(i)
          }
        })
      }

      if (examineAll) {
        examineAll = false
      }

      else if (changed === 0) {
        examineAll = true
      }
    }

    this.trained = true
  }

  examine (i2) {
    this.y2 = this.y[i2]
    this.x2 = this.x[i2]
    this.a2 = this.alpha[i2]
    this.e2 = this.cachedError(i2)

    const nonZeroNonCAlpha = [], r2 = this.e2 * this.y2

    if (
      // KKT conditions
      (r2 < -this.tolerance && this.a2 < this.c) ||
      (r2 > this.tolerance && this.a2 > 0)
    ) {
      // Tally non-zero and non-C alphas
      this.alpha.forEach((ai, i) => {
        if (ai > 0 && ai < this.c) {
          nonZeroNonCAlpha.push(i)
        }
      })

      // Second heuristic, attempt 1
      if (nonZeroNonCAlpha.length > 1) {
        let i1, max = 0, stepSize

        nonZeroNonCAlpha.forEach((j) => {
          stepSize = Math.abs((this.error[j] - this.y[j]) - this.e2)

          if (stepSize > max) {
            max = stepSize
            i1 = j
          }
        })

        if (Util.isNum(i1) && this.step(i1, i2)) {
          return 1
        }
      }

      // Second heuristic, attempt 2
      const randPartialSequence = Util.randSequence(nonZeroNonCAlpha)

      // .some will cease execution once the first truthy value is called back
      if (randPartialSequence.some((i) => this.step(i, i2))) {
        return 1
      }

      // Second heuristic, attempt 3
      // eslint-disable-next-line no-unused-vars
      const fullSequence = Array(this.m).fill(0).reduce((x, xs, i) => {
        x.push(i)

        return x
      }, [])

      const randFullSequence = Util.randSequence(fullSequence)

      // .some will cease execution once the first truthy value is called back
      if (randFullSequence.some((i) => this.step(i, i2))) {
        return 1
      }
    }

    // If step is not taken, return 0 as amount of steps taken
    return 0
  }

  step(i1, i2) {
    // Occurs in rare cases if all step sizes from second heuristic are < 0
    if (!Util.isNum(i1)) {
      return false
    }

    // If both indices are the same, don't step
    if (i1 === i2) {
      return false
    }

    const
      a1 = this.alpha[i1],
      y1 = this.y[i1],
      x1 = this.x[i1],
      e1 = this.cachedError(i1),
      s = y1 * this.y2,
      k11 = this.kern(x1, x1),
      k12 = this.kern(x1, this.x[i2]),
      k22 = this.kern(this.x[i2], this.x[i2]),
      eta = k11 + k22 - 2 * k12

    let a2New, l, h

    if (y1 === this.y2) {
      l = Math.max(0, this.a2 + a1 - this.c)
      h = Math.min(this.c, this.a2 + a1)
    }

    else {
      l = Math.max(0, this.a2 - a1)
      h = Math.min(this.c, this.c + this.a2 - a1)
    }

    if (l === h) {
      return false
    }

    if (eta > 0) {
      a2New = this.a2 + this.y2 * (e1 - this.e2) / eta

      if (a2New < l) {
        a2New = l
      }

      else if (a2New > h) {
        a2New = h
      }
    }

    else {
      const
        f1 = y1 * (e1 + this.b) - a1 * k11 - s * this.a2 * k12,
        f2 = this.y2 * (this.e2 + this.b) - s * a1 * k12 - this.a2 * k22,
        l1 = a1 + s * (this.a2 - l),
        h1 = a1 + s * (this.a2 - h)

      const psiL = l1 * f1 + l * f2 + 0.5 * Math.pow(l1, 2) * k11
        + 0.5 * Math.pow(l, 2) * k22 + s * l * l1 * k12

      const psiH = h1 * f1 + h * f2 + 0.5 * Math.pow(h1, 2) * k11
        + 0.5 * Math.pow(h, 2) * k22 + s * h * h1 * k12

      if (psiL < psiH - this.tolerance) {
        a2New = l
      }

      else if (psiL > psiH + this.tolerance) {
        a2New = h
      }

      else {
        a2New = this.a2
      }
    }

    const changeNegligible = Math.abs(a2New - this.a2) < this.tolerance
      * (a2New + this.a2 + this.tolerance)

    if (changeNegligible) {
      return false
    }

    // Solve for B
    let bNew

    const a1New = a1 + s * (this.a2 - a2New)

    const b1 = e1 + y1 * (a1New - a1) * k11 + this.y2
      * (a2New - this.a2) * k12 + this.b

    const b2 = this.e2 + y1 * (a1New - a1) * k12 + this.y2
      * (a2New - this.a2) * k22 + this.b

    if (0 < a1 && a1 < this.c) {
      bNew = b1
    }

    else if (0 < this.a2 && this.a2 < this.c) {
      bNew = b2
    }

    else {
      bNew = 0.5 * (b1 + b2)
    }

    const bChange = bNew - this.b

    this.b = bNew

    // Solve for W
    if (this.kernel === "linear") {
      const wlm1 = x1.map((v) => {
        return y1 * (a1New - a1) * v
      })

      const wlm2 = this.x2.map((v) => {
        return this.y2 * (a2New - this.a2) * v
      })

      this.w = Formula.vectorSum(this.w, Formula.vectorSum(wlm1, wlm2))
    }

    // Update error cache
    const lm1 = y1 * (a1New - a1), lm2 = this.y2 * (a2New - this.a2)

    // eslint-disable-next-line no-unused-vars
    Array(this.m).fill(0).forEach((mi, i) => {
      if (0 < this.alpha[i] && this.alpha[i] < this.c) {
        this.error[i] += lm1 * this.kern(x1, this.x[i]) + lm2
          * this.kern(this.x2, this.x[i]) - bChange
      }
    })

    this.error[i1] = 0
    this.error[i2] = 0
    this.alpha[i1] = a1New
    this.alpha[i2] = a2New

    return true
  }

  // Returns cached error, otherwise finds SVM output
  cachedError (i) {
    // KKT condition, the bounds constraint
    if (0 < this.alpha[i] && this.alpha[i] < this.c) {
      return this.error[i]
    }

    if (this.kernel === "linear") {
      return (Formula.dotProduct(this.w, this.x[i]) - this.b) - this.y[i]
    }

    return this.nonLinearOutput(i) - this.y[i]
  }

  nonLinearOutput (i) {
    const output = this.alpha.map((aj, j) => {
      return aj * this.y[j] * this.kern(this.x[j], this.x[i])
    }).reduce((x, xs) => x + xs, 0)

    return output - this.b
  }

  classify (x) {
    if (!this.trained) {
      const errMsg = `
        Cannot classify vector input with an SVM that has not yet been trained
      `

      throw new Error(errMsg)
    }

    // Using a negative for 'b' because we use the w * x - b = 0 formula
    if (this.kernel === "linear") {
      return Formula.hypothesis(this.w, x, -this.b)
    }

    const margin = this.alpha.reduce((a, as, i) => {
      return a + (as * this.y[i] * this.kern(x, this.x[i]))
    }, -this.b)

    return Formula.sign(margin)
  }

  classifyList (xs) {
    return xs.map((x) => this.classify(x))
  }

  hyperplane () {
    if (!this.trained) {
      const errMsg = `
        The SVM being referenced has not been trained, and therefore contains
        no hyperplane
      `

      throw new Error(errMsg)
    }

    if (this.kernel === "linear") {
      return this.w
    }

    // If linear kernel isn't being used, return Lagrange multipliers
    return this.alpha
  }

  offset () {
    if (!this.trained) {
      const errMsg = `
        The SVM being referenced has not been trained, and therefore contains
        no computed 'b' offset value
      `

      throw new Error(errMsg)
    }

    // Using a negative for 'b' because we use the w * x - b = 0 formula
    return -this.b
  }
}

},{"../env/defaults":1,"./formula":3,"./kernel":4,"./util":6}],6:[function(require,module,exports){
module.exports = {
  isArr,
  isKernel,
  isNum,
  randSequence,
}

// isArr :: [ a ] -> Bool
function isArr (xs) {
  return Array.isArray(xs)
}

// isKernel :: a -> Bool
function isKernel (x) {
  // TODO: Update when polynomial kernel function is added
  if (x === "gaussian" || x === "linear") {
    return true
  }

  return false
}

// isNum :: a -> Bool
function isNum (x) {
  return typeof(x) === "number" && !isNaN(x)
}

/* randSequence takes a list (which, in the case of the SMO, will contain
** only numbers), and return a list of the same values with a different
** "starting point". This is not a pure function, but is necessary for a
** proper implementation of the SMO algorithm.
**
** Example:
** randSequence([ 2, 4, 6, 8, 10, 12, 14, 16, 18, 20 ])
** => [ 10, 12, 14, 16, 18, 20, 2, 4, 6, 8 ]
*/
// randSequence :: [ a ] -> [ a ]
// TODO: Type checking/unit tests for this
function randSequence(ls) {
  const
    randPoint = Math.floor(Math.random() * ls.length),
    listHead = ls.slice(randPoint),
    listTail = ls.reverse().slice(ls.length - randPoint).reverse()

  return listHead.concat(listTail)
}

},{}],7:[function(require,module,exports){
const Inferrer = require("inferrer")

/* 
https://coderwall.com/p/iyhizq/get-the-pixel-data-of-an-image-in-html
function getPixel(url, x, y) {
  var img = new Image();
  img.src = url;
  var canvas = document.createElement('canvas');
  var context = canvas.getContext('2d');
  context.drawImage(img, 0, 0);
  return context.getImageData(x, y, 1, 1).data;
}
getPixel('./bg.png', 50, 50); // [255, 255, 255, 0];
*/
/* 
so are Image & HTMLImage interchangeable? 
I.e. if I already have an HTMLImage, then it can be assumed I already have an Image()? 
const image = new Image();
image.src = "plumeria.jpg";
*/
function getPixelData(imgElement) {
//	const image = new Image();
//	image.src = "cat.jpg";
//image.addEventListener("load", () => {
	// todo: make sure these arguments match up
		//imgElement.setAttribute('crossOrigin', '');
		const canvas = document.getElementById('image-pixel-data');
		const ctx = canvas.getContext('2d');
		ctx.drawImage(imgElement, 
					// with orign at top left cornern, place image at X, Y coordinates 
					0, 0, 
					// destination width, dheight (not entirely sure what these mean)
					50, 50);
		// source = original image 
		// s = source 					sx  sy	sw  sh	
 const imageData = ctx.getImageData(0, 0, 50, 50);
	// here we actually paint the image onto the canvas, so don't think I need this part 
	  ctx.putImageData(imageData, 0, 0);
	// I don't care about displaying the image, so I think I only need to return the gotten image data? 
	return imageData // fed into nj.array e.g. nj.array(getPixel(dogImage))
//})
}

// window.setTimeout was a quick hack to ensure OpenCV had loaded, though I assumed it'd load synchronously 
// https://stackoverflow.com/a/63211547
		function get_pixel_data_OpenCV(imgElement) {
			let matrix = cv.imread(imgElement); // calls context.getImageData :| 
			//console.log(matrix)
			return matrix
		} 
		
		let training_data = []
		const appendToTrainingData = (imageElements) => {
			Array.from(imageElements).map(imageElement => {
					/* np = nj = numjs library (so far it looks like the same API as Numpy)
					am I able to do 
					const pet_img = nj.array(dogImage.src) 
					*/
					// do I need opencv? or is having access to the img src enough? 
					// or do I need to use OpenCV to open/load the image 
					/* 
					not sure if I need OpenCV yet, I believe I can using HTML/JS to get the actual pixel data 
					But I need to load the images onto a (hidden) canvas 
					then I believe getImageData is a method of the context object 
					*/
					// https://stackoverflow.com/questions/22097747/how-to-fix-
					// I can't ignore the error mentioned in that SO post because I need getImageData to be called 
					// so I think (so long as I do not have access to the server hosting my website) 
					// I need to use local images 
					// this is another reason that a server (one I can actually manipulate as opposed to Github Pages etc) may be inevitable ; will know more when I look into the HTML5 file upload API e.g. where do the images live? Are they on the same origin as the ML script? 
					const pet_image = getPixelData(imageElement) 
					//const pet_image = get_pixel_data_OpenCV(imageElement) 
					// console.log(pet_image)
					// now I can push the pixels as a numpy array along with their labels to the training_data 
					// I'm not quite a fan of storing the pixel array and the label as a sub array, 
					// I'd rather use a key-value pair, but I believe the example I am basing the code does 
					// it this way 
					training_data.push([nj.array(pet_image), imageElement.dataset.label])	
					
					// then i'd do something like 
					/* 
					const img = cv.imread(dogImage.src)
					// resize (the HTML image elements are 50X50) 
					// const resized = cv.resize(img, [50, 50])
					training_data.push(np.array(pet_img), dogImage.dataset.label)	
					*/
					//training_data.push(dogImage, dogImage.dataset.label)
			})
		} 
		
		function shuffle(array) {
			let currentIndex = array.length,  randomIndex;
			
			// While there remain elements to shuffle.
			while (currentIndex > 0) {
				
				// Pick a remaining element.
				randomIndex = Math.floor(Math.random() * currentIndex);
				currentIndex--;
				
				// And swap it with the current element.
				[array[currentIndex], array[randomIndex]] = [
					array[randomIndex], array[currentIndex]];
				}
				
				return array;
			}
			
			
			const dogImages = document.querySelectorAll('img[data-label="dog"]');
			const catImages = document.querySelectorAll('img[data-label="cat"]');
			console.log("updated")
			appendToTrainingData(dogImages)
			appendToTrainingData(catImages) 
			const training_data_shuffled = shuffle(training_data)
			
			/* 
			now the data should be prepared to pass into a machine learning model 
			e.g. SVM, RF, or conv net 
			But remember training_data is not a flattened array 
			& I'm not sure how the flattening would work if the pixel data is mixed with the labels :|
			*/
			
			
			/* 
			original Python code from: 
			D:\software-dev-2\machine-learning\classical-models\train-svm.py
			for feature, label in data:
			features.append(feature)
	labels.append(label)
	^ so I guess feature, label is kind of like destructuring, hence I could merely use a dictionary (an object literal or a Map)
	
	my data looks like: [Array(2), ...] 
	so I could have a loop which for the odd numbers e.g. n % 1 == 0 is the actual pixel data 
	& n % 2 == 0 is the actual label? 
	*/	
	
	let features = []
	let labels = []
	training_data_shuffled.forEach((element, index) => {
		features.push(element[0])
		if (element[1].toLowerCase() == "dog") {	
			labels.push(0)
		}
		if (element[1].toLowerCase() == "cat") {	
			labels.push(1)
		}
		
		/* 
		if (index % 1 == 0) {
			features.push(element)
		} 
		if (index % 2 == 0) {
			if (element == "dog") {
				labels.push(0)
			}
			if (element == "cat") {
                labels.push(1)
			}
		}	
		*/ 
	})
	
    let XOR_training_data = []
    //{ input: [ 1, 0 ], classification: 1 },
	training_data_shuffled.forEach((element, index) => {
        //const input = [1, 1, -1] // element[0]
        //console.log(element[0].selection.data[0])
        const { data } = element[0].selection
        console.log(data[0].data)
//View1darray.data.ImageData
        let obj = {
            input: [2,2] // element[0].data.imageData.data
        }
		if (element[1].toLowerCase() == "dog") {	
            obj.classification = 1 
        }
		if (element[1].toLowerCase() == "cat") {	
            obj.classification = -1 
        }
        console.log(obj) 
        XOR_training_data.push(obj)
	})
	


    /* 
	ok, the data is ready to be passed to the machine learning model 
	it would be nice if I was able to save this data & then load it into the Python SVM 
	and the Python conv net (e.g. Sentdex's model) 
	But A. I can't be bothered B. at the moment there's such little data it'd be hard to know if its actually working 
	*/ 
	
	/* note: I sense that we are entering into hardware accelerated computing e.g. WebGL or WebAssembly etc, I originally assumed that there would be an SVM module in pure ES5 JavaScript, but it'd seem that if I was/am really concerned with the SVM working on say a legacy browser within a budget smartphone... then I may need to code the SVM myself in pure ES5 (or lower, then its like "ohh well, just write it in Flash :P") , I am yet to confirm 
	if a TensorflowJS convolutional neural network is pure JavaScript or if there's some performance trickery going on where its assumed legacy browsers are not being used 
	*/ 
	
	const XOR = new Inferrer({ kernel: "gaussian", gamma: 2 })
	
	// I made the preprocessing code before looking at this library :| 
	// so, why is "-1"? is this representing a class? e.g. dog = 1, cat = -1? can I use 0 instead? 
	// also I'm not entirely sure if I am understanding XOR , is it just another name for binary classifier
	// or is it a binary classifer for a more specific purpose e.g. "the XOR problem?" (which I assumed was another name 
	// for binary classification)
	// element = [feature, label] 
    /* 
	let XOR_training_data = training_data_shuffled.map((element, index) => {
		// just a quick hack to make sure the Inferrence library is working (will obviously need to use more robost code)
		if (index < 1) { console.log("Validation sample: ", element[1]) }
		if (index >= 1) {
			let feature = element[0]
			let label = null // dog = 1, cat = -1 
			if (element[1].toLowerCase() == "dog") {	
				label = 1
			}
			if (element[1].toLowerCase() == "cat") {	
				label = -1 
			}
            console.log("Feature array: ", array)
            // I think these need to be input: flatten(feature) ? refer to the Python SVM & CNN code 
			return {input: [ 0, 0 ], classification: label}
		}
	})
    console.log("XOR_TRAINING_DATA:")
    */ 
/* 
  const XOR_training_data = [{ input: [ 0, 0 ], classification: -1 },
  { input: [ 0, 1 ], classification: 1 },
  { input: [ 1, 1 ], classification: -1 }] 
  */
	XOR.train(XOR_training_data)
	
	const prediction = XOR.classify(XOR_training_data[0].input)
	console.log("prediction: ", prediction)

},{"inferrer":2}]},{},[7]);
